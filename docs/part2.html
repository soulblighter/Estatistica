<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Rodrigo, Robson, Julio, Flavio" />


<title>Parte 2</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Avaliação de técnicas de mineração de dados</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Trabalho</a>
</li>
<li>
  <a href="part1.html">Parte 1</a>
</li>
<li>
  <a href="part2.html">Parte 2</a>
</li>
<li>
  <a href="part3.html">Parte 3</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Parte 2</h1>
<h4 class="author">Rodrigo, Robson, Julio, Flavio</h4>
<h4 class="date">26/01/2020</h4>

</div>


<div id="etapa-2---classificação-por-vinhos-bom-ou-ruim" class="section level2">
<h2>Etapa 2 - Classificação por vinhos “Bom” ou “Ruim”</h2>
</div>
<div id="regressão-logística" class="section level2">
<h2>Regressão Logística</h2>
<p>Vamos tratar a base de dados para tentar descobrir se um vinho é Bom ou Ruim através de suas características físico químicas. Consideramos que vinhos com nota &gt;=6 são de boa qualidade (Bom) e as outras notas com qualidade Ruim. Criaremos uma nova variável (newQuality), que possui valor= 1 quando o vinho é Bom e 0 Se for ruim</p>
<pre class="r"><code>library(readr)
BaseWine_Red_e_White &lt;- read_delim(&quot;BaseWine_Red_e_White.csv&quot;, 
     &quot;;&quot;, escape_double = FALSE, col_types = cols(Vinho = col_factor(levels = c(&quot;WHITE&quot;, 
         &quot;RED&quot;))), locale = locale(date_names = &quot;pt&quot;, 
         decimal_mark = &quot;,&quot;, grouping_mark = &quot;.&quot;), 
     trim_ws = TRUE)

# remove duplicatas
BaseWine_Red_e_White &lt;- BaseWine_Red_e_White %&gt;% distinct()

# remove outliers
for (x in c(&quot;fixedacidity&quot;, &quot;volatileacidity&quot;, &quot;citricacid&quot;,
                    &quot;residualsugar&quot;, &quot;chlorides&quot;, &quot;freesulfurdioxide&quot;,
                    &quot;totalsulfurdioxide&quot;, &quot;density&quot;, &quot;pH&quot;,
                    &quot;sulphates&quot;, &quot;alcohol&quot;)) {

  outliers &lt;- boxplot(BaseWine_Red_e_White[[x]], plot=FALSE, range=3)$out

  if( !is.null(outliers) &amp; length(outliers) &gt; 0 ) {
    BaseWine_Red_e_White &lt;- BaseWine_Red_e_White[-which(BaseWine_Red_e_White[[x]] %in% outliers),]
  }
}


BaseQuality &lt;- BaseWine_Red_e_White
BaseQuality$newQuality &lt;- ifelse(BaseQuality$quality &gt;=6, 1, 0)

drops &lt;- c(&quot;id_vinho&quot;, &quot;Vinho&quot;, &quot;quality&quot;)

BaseQuality &lt;- BaseQuality[ , !(names(BaseQuality) %in% drops)]
#head(BaseQuality)</code></pre>
<p>Vamos separar a base de dados em duas: Base de treino e de teste</p>
<pre class="r"><code>smp_size &lt;- floor(0.75 * nrow(BaseQuality))
set.seed(1)
trainind &lt;- sample(seq_len(nrow(BaseQuality)), size = smp_size)

train &lt;- BaseQuality[trainind, ]
test &lt;- BaseQuality[-trainind, ]</code></pre>
<p>Vamos criar agora um modelo de regressão logística atráves da função glm</p>
<pre class="r"><code>modeloQuality &lt;- glm(newQuality ~ fixedacidity + volatileacidity+ citricacid+ residualsugar+ chlorides+freesulfurdioxide+totalsulfurdioxide+density+ pH+ sulphates+ alcohol, train, family=binomial(link=logit))
summary(modeloQuality)</code></pre>
<pre><code>## 
## Call:
## glm(formula = newQuality ~ fixedacidity + volatileacidity + citricacid + 
##     residualsugar + chlorides + freesulfurdioxide + totalsulfurdioxide + 
##     density + pH + sulphates + alcohol, family = binomial(link = logit), 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7912  -0.8830   0.4221   0.7955   2.4464  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         42.305794  57.635108   0.734 0.462932    
## fixedacidity         0.089989   0.068808   1.308 0.190933    
## volatileacidity     -4.363693   0.349215 -12.496  &lt; 2e-16 ***
## citricacid          -0.724160   0.319127  -2.269 0.023257 *  
## residualsugar        0.082187   0.022956   3.580 0.000343 ***
## chlorides           -2.219840   2.777154  -0.799 0.424104    
## freesulfurdioxide    0.021932   0.003155   6.953 3.58e-12 ***
## totalsulfurdioxide  -0.007446   0.001079  -6.900 5.20e-12 ***
## density            -53.875078  58.737661  -0.917 0.359030    
## pH                   0.627515   0.376767   1.666 0.095808 .  
## sulphates            2.425217   0.363601   6.670 2.56e-11 ***
## alcohol              0.918624   0.078716  11.670  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 6070.2  on 4634  degrees of freedom
## Residual deviance: 4720.5  on 4623  degrees of freedom
## AIC: 4744.5
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Aplicando os valores preditos na amostra. Temos um resumo da variável de predição e o histograma da distribuição</p>
<pre class="r"><code>train$predito &lt;- fitted(modeloQuality)
summary(train$predito)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.02986 0.43909 0.68091 0.63754 0.85869 0.99230</code></pre>
<pre class="r"><code>hist(train$predito)</code></pre>
<p><img src="part2_files/figure-html/predvalhist-1.png" width="672" /></p>
<p>Frequências Absolutas da variável predita</p>
<pre class="r"><code>train$fx_predito1 &lt;- cut(train$predito, breaks=c(0,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1), right=F)
table(train$fx_predito1,train$newQuality)</code></pre>
<pre><code>##            
##               0   1
##   [0,0.1)    43   6
##   [0.1,0.2) 169  38
##   [0.2,0.3) 237  75
##   [0.3,0.4) 272 139
##   [0.4,0.5) 236 203
##   [0.5,0.6) 223 258
##   [0.6,0.7) 178 338
##   [0.7,0.8) 162 445
##   [0.8,0.9) 118 706
##   [0.9,1)    42 747</code></pre>
<p>Frequências relativas</p>
<pre class="r"><code>print(prop.table(table(train$fx_predito1,train$newQuality),2), digits=2)</code></pre>
<pre><code>##            
##                 0     1
##   [0,0.1)   0.026 0.002
##   [0.1,0.2) 0.101 0.013
##   [0.2,0.3) 0.141 0.025
##   [0.3,0.4) 0.162 0.047
##   [0.4,0.5) 0.140 0.069
##   [0.5,0.6) 0.133 0.087
##   [0.6,0.7) 0.106 0.114
##   [0.7,0.8) 0.096 0.151
##   [0.8,0.9) 0.070 0.239
##   [0.9,1)   0.025 0.253</code></pre>
<pre class="r"><code>plot(train$fx_predito1 , train$newQuality)</code></pre>
<p><img src="part2_files/figure-html/predfreqrel2-1.png" width="672" /></p>
<p>Vamos montar a matriz de confusão. Para o corteurte, vamos escolher o 0,5</p>
<pre class="r"><code>train$fx_predito &lt;- cut(train$predito, breaks=c(0,0.50,1), right=F)
MC_log_treino &lt;- table(train$newQuality, train$fx_predito , deparse.level = 2) 
show(MC_log_treino)</code></pre>
<pre><code>##                 train$fx_predito
## train$newQuality [0,0.5) [0.5,1)
##                0     957     723
##                1     461    2494</code></pre>
<pre class="r"><code>ACC_log = sum(diag(MC_log_treino))/sum(MC_log_treino)*100   
show(ACC_log) </code></pre>
<pre><code>## [1] 74.45523</code></pre>
<p>O Modelo teve uma acurácia de 73%, que pode ser um bom resultado dependendo do nível de confiança adotado.</p>
</div>
<div id="aplicando-modelo" class="section level2">
<h2>Aplicando Modelo</h2>
<p>Vamos agora aplicar o modelo na amostra de teste.</p>
<pre class="r"><code>predito_log_teste &lt;- predict(modeloQuality,test,type = &quot;response&quot;)
summary(predito_log_teste)   </code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.04255 0.44014 0.67707 0.63606 0.85602 0.99402</code></pre>
<p>Em seguida vamos plotar a distribuição da variável predita</p>
<pre class="r"><code>hist(predito_log_teste)  </code></pre>
<p><img src="part2_files/figure-html/testeSumplot-1.png" width="672" /></p>
<p>Matriz de Confusão para a variável predita</p>
<pre class="r"><code>test$Qual &lt;- cut(predito_log_teste , breaks=c(0,0.50,1), right=F)
MC_test_log &lt;- table(test$newQuality, test$Qual , deparse.level = 2) 
show(MC_test_log)</code></pre>
<pre><code>##                test$Qual
## test$newQuality [0,0.5) [0.5,1)
##               0     306     234
##               1     169     837</code></pre>
<p>Vamos calcular a acurácia do modelo na amostra teste.</p>
<pre class="r"><code>ACC_test_log = sum(diag(MC_test_log))/sum(MC_test_log)*100  
show(ACC_test_log) </code></pre>
<pre><code>## [1] 73.93273</code></pre>
<p>Percebemos que o valor observado é próximo à amostra de teste. Podemos dizer que modelo não teve overfit aparente em relação aos dados treino.</p>
<pre class="r"><code>plot(test$Qual , test$newQuality)</code></pre>
<p><img src="part2_files/figure-html/testePlot-1.png" width="672" /></p>
<p>Percebemos que o modelo é muito bom para identificar vinhos Bons utilizando a amostra de teste. Entretanto, para identificar vinhos de qualidade inferior, o modelo não é tão preciso</p>
<pre class="r"><code>print(prop.table(table(test$Qual ,test$newQuality),2),digits=2)</code></pre>
<pre><code>##          
##              0    1
##   [0,0.5) 0.57 0.17
##   [0.5,1) 0.43 0.83</code></pre>
</div>
<div id="arvore-de-decisão" class="section level2">
<h2>Arvore de Decisão</h2>
<p>Vamos Limpar a memória do R e importar novamente as informações de Vinhos</p>
<pre class="r"><code>library(readr)
BaseWine_Red_e_White &lt;- read_delim(&quot;BaseWine_Red_e_White.csv&quot;, 
     &quot;;&quot;, escape_double = FALSE, col_types = cols(Vinho = col_factor(levels = c(&quot;WHITE&quot;, 
         &quot;RED&quot;))), locale = locale(date_names = &quot;pt&quot;, 
         decimal_mark = &quot;,&quot;, grouping_mark = &quot;.&quot;), 
     trim_ws = TRUE)

# remove duplicatas
BaseWine_Red_e_White &lt;- BaseWine_Red_e_White %&gt;% distinct()

# remove outliers
for (x in c(&quot;fixedacidity&quot;, &quot;volatileacidity&quot;, &quot;citricacid&quot;,
                    &quot;residualsugar&quot;, &quot;chlorides&quot;, &quot;freesulfurdioxide&quot;,
                    &quot;totalsulfurdioxide&quot;, &quot;density&quot;, &quot;pH&quot;,
                    &quot;sulphates&quot;, &quot;alcohol&quot;)) {

  outliers &lt;- boxplot(BaseWine_Red_e_White[[x]], plot=FALSE, range=3)$out

  if( !is.null(outliers) &amp; length(outliers) &gt; 0 ) {
    BaseWine_Red_e_White &lt;- BaseWine_Red_e_White[-which(BaseWine_Red_e_White[[x]] %in% outliers),]
  }
}


BaseQuality &lt;- BaseWine_Red_e_White
BaseQuality$newQuality &lt;- ifelse(BaseQuality$quality &gt;=6, 1, 0)
BaseQuality$newQuality &lt;- factor(BaseQuality$newQuality)
drops &lt;- c(&quot;id_vinho&quot;, &quot;Vinho&quot;, &quot;quality&quot;)


BaseQuality &lt;- BaseQuality[ , !(names(BaseQuality) %in% drops)]
head(BaseQuality)</code></pre>
<pre><code>## # A tibble: 6 x 12
##   fixedacidity volatileacidity citricacid residualsugar chlorides
##          &lt;dbl&gt;           &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;
## 1          6.6            0.24       0.35           7.7     0.031
## 2          6.7            0.34       0.43           1.6     0.041
## 3         10.6            0.31       0.49           2.2     0.063
## 4          5.4            0.18       0.24           4.8     0.041
## 5          6.7            0.3        0.44          18.8     0.057
## 6          6.8            0.5        0.11           1.5     0.075
## # ... with 7 more variables: freesulfurdioxide &lt;dbl&gt;, totalsulfurdioxide &lt;dbl&gt;,
## #   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, newQuality &lt;fct&gt;</code></pre>
<p>Vamos separar a base de treino e de teste</p>
<pre class="r"><code>smp_size &lt;- floor(0.75 * nrow(BaseQuality))
set.seed(1)
trainind &lt;- sample(seq_len(nrow(BaseQuality)), size = smp_size)

train &lt;- BaseQuality[trainind, ]
test &lt;- BaseQuality[-trainind, ]</code></pre>
<p>Em seguida vamos criar um modelo de árvore de decisão a partir da amostra de teste. A árvore sugerida pelo modelo é a seguinte:</p>
<p>O modelo sugere um alto peso para o teor alcoolico e em segundo nível para a acidez volátil</p>
<pre class="r"><code>modelo_tree_1 &lt;- rpart (newQuality ~ fixedacidity + volatileacidity+ citricacid+ residualsugar+ chlorides+freesulfurdioxide+totalsulfurdioxide+density+ pH+ sulphates+ alcohol, data = train, control = rpart.control(cp = 0.05))

rpart.plot(modelo_tree_1)</code></pre>
<p><img src="part2_files/figure-html/model2-1.png" width="672" /></p>
<p>Vamos ver o resumo da execução do modelo:</p>
<pre class="r"><code>summary(modelo_tree_1)</code></pre>
<pre><code>## Call:
## rpart(formula = newQuality ~ fixedacidity + volatileacidity + 
##     citricacid + residualsugar + chlorides + freesulfurdioxide + 
##     totalsulfurdioxide + density + pH + sulphates + alcohol, 
##     data = train, control = rpart.control(cp = 0.05))
##   n= 4635 
## 
##          CP nsplit rel error    xerror       xstd
## 1 0.1601190      0 1.0000000 1.0000000 0.01948046
## 2 0.1321429      1 0.8398810 0.9029762 0.01901502
## 3 0.0500000      2 0.7077381 0.7160714 0.01776529
## 
## Variable importance
##            alcohol            density    volatileacidity          chlorides 
##                 36                 17                 12                 10 
##      residualsugar totalsulfurdioxide  freesulfurdioxide 
##                 10                  9                  5 
## 
## Node number 1: 4635 observations,    complexity param=0.160119
##   predicted class=1  expected loss=0.3624595  P(node) =1
##     class counts:  1680  2955
##    probabilities: 0.362 0.638 
##   left son=2 (2095 obs) right son=3 (2540 obs)
##   Primary splits:
##       alcohol         &lt; 10.11667 to the left,  improve=311.18460, (0 missing)
##       density         &lt; 0.992105 to the right, improve=163.49140, (0 missing)
##       chlorides       &lt; 0.0395   to the right, improve=125.13410, (0 missing)
##       volatileacidity &lt; 0.2425   to the right, improve= 93.25104, (0 missing)
##       citricacid      &lt; 0.235    to the left,  improve= 86.47079, (0 missing)
##   Surrogate splits:
##       density            &lt; 0.995395 to the right, agree=0.766, adj=0.483, (0 split)
##       chlorides          &lt; 0.0435   to the right, agree=0.671, adj=0.272, (0 split)
##       residualsugar      &lt; 7.05     to the right, agree=0.668, adj=0.265, (0 split)
##       totalsulfurdioxide &lt; 143.5    to the right, agree=0.661, adj=0.249, (0 split)
##       freesulfurdioxide  &lt; 43.75    to the right, agree=0.615, adj=0.147, (0 split)
## 
## Node number 2: 2095 observations,    complexity param=0.1321429
##   predicted class=0  expected loss=0.4357995  P(node) =0.4519957
##     class counts:  1182   913
##    probabilities: 0.564 0.436 
##   left son=4 (1563 obs) right son=5 (532 obs)
##   Primary splits:
##       volatileacidity   &lt; 0.235    to the right, improve=106.17090, (0 missing)
##       citricacid        &lt; 0.245    to the left,  improve= 35.69798, (0 missing)
##       chlorides         &lt; 0.0645   to the right, improve= 34.41895, (0 missing)
##       residualsugar     &lt; 10.15    to the left,  improve= 27.81579, (0 missing)
##       freesulfurdioxide &lt; 25.5     to the left,  improve= 17.44151, (0 missing)
##   Surrogate splits:
##       pH                &lt; 2.945    to the right, agree=0.754, adj=0.030, (0 split)
##       chlorides         &lt; 0.0295   to the right, agree=0.749, adj=0.011, (0 split)
##       freesulfurdioxide &lt; 99.5     to the left,  agree=0.748, adj=0.009, (0 split)
##       density           &lt; 0.99166  to the right, agree=0.748, adj=0.008, (0 split)
##       sulphates         &lt; 0.335    to the right, agree=0.747, adj=0.002, (0 split)
## 
## Node number 3: 2540 observations
##   predicted class=1  expected loss=0.196063  P(node) =0.5480043
##     class counts:   498  2042
##    probabilities: 0.196 0.804 
## 
## Node number 4: 1563 observations
##   predicted class=0  expected loss=0.3429303  P(node) =0.3372168
##     class counts:  1027   536
##    probabilities: 0.657 0.343 
## 
## Node number 5: 532 observations
##   predicted class=1  expected loss=0.2913534  P(node) =0.1147789
##     class counts:   155   377
##    probabilities: 0.291 0.709</code></pre>
<p>Vamos aplicar a árvore de decisão na amostra de teste Em seguida exibiremos a matriz de confusão</p>
<pre class="r"><code>predTree &lt;-predict(modelo_tree_1,test,type=&#39;class&#39;)
MCpredTree&lt;-table(test$newQuality, predTree)
MCpredTree</code></pre>
<pre><code>##    predTree
##       0   1
##   0 319 221
##   1 193 813</code></pre>
<p>Em seguida vamos calcular a acurácia do modelo de árvore de decisão. Podemos ver que o resultado(73,66%) é muito próximo ao obtido no modelo de regressão logística (72,92%)</p>
<pre class="r"><code>diagonal &lt;- diag(MCpredTree)
Acc_tree_teste &lt;- sum(diagonal)/sum(MCpredTree)
print(Acc_tree_teste*100, digits=5)</code></pre>
<pre><code>## [1] 73.221</code></pre>
<p>Vamos calcular a matriz de confusão relativa.</p>
<pre class="r"><code>print(prop.table(table(predTree,test$newQuality),2),digits=2)</code></pre>
<pre><code>##         
## predTree    0    1
##        0 0.59 0.19
##        1 0.41 0.81</code></pre>
<p>Assim como o modelo de regressão logística, a acurácia é muito maior para identificar vinhos Bons. Entretanto, o modelo de árvore de decisão apresentado consegue prever melhor (60%) os casos em que os vinhos não são de boa qualidade no outro modelo (56%)</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
